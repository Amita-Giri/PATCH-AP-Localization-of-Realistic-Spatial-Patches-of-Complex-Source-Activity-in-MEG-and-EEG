{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fcac3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "import sys; sys.path.insert(0, current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "710ed510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pickle as pkl\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from SimFunction import SimulationGenerator\n",
    "from TimeCourses import TimeCourse\n",
    "from invert.util import pos_from_forward\n",
    "from scipy.spatial.distance import cdist\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e3cd2",
   "metadata": {},
   "source": [
    "#### =========================================================================\n",
    "#### Section 1: Setup and Loading the Forward Model\n",
    "#### This section loads the pre-computed forward model and sensor information,\n",
    "#### which are essential for linking brain source activity to sensor signals.\n",
    "#### It also defines a helper function to save data and creates a directory\n",
    "#### to store the simulation outputs.\n",
    "#### =========================================================================\n",
    "#### Specify the path to the directory containing the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "291304e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forward_models\\\\128_ch_coarse_80_ratio-fwd.fif'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"forward_models\"\n",
    "folder_path = os.path.join(file_path, \"128_ch_coarse_80_ratio-fwd.fif\")\n",
    "folder_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba5e4cb",
   "metadata": {},
   "source": [
    "#### Read the forward solution from the specified file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b6da792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Changing to fixed-orientation forward solution with surface-based source orientations...\n",
      "    [done]\n"
     ]
    }
   ],
   "source": [
    "fwd_for = mne.read_forward_solution(folder_path, verbose=0)\n",
    "fwd_for = mne.convert_forward_solution(fwd_for, force_fixed=True)\n",
    "\n",
    "fn = os.path.join(file_path, \"128_ch_info.fif\")\n",
    "info = mne.io.read_info(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e85aecc",
   "metadata": {},
   "source": [
    "#### Define a function to save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e176d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data_dict, folder_path, filename):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pkl.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97699859",
   "metadata": {},
   "source": [
    "#### Define the folder path for Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c38e8a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"Simulated_Data\"\n",
    "folder_path = os.path.join(os.getcwd(), folder_name)\n",
    "os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5200ab49",
   "metadata": {},
   "source": [
    "#### =========================================================================\n",
    "#### Section 2: Main Simulation Loop\n",
    "#### This is the core of the script, where nested loops iterate through\n",
    "#### different experimental conditions like source correlation, spatial smoothness,\n",
    "#### patch complexity (Patchranks), and signal-to-noise ratio (SNR).\n",
    "#### For each combination of parameters, it generates and saves a batch of data.\n",
    "#### ========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f600953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5143683160753044\n",
      "Elapsed time for corr_coeff=0.5, Smoothness_order=2, Patchranks=[1, 2], snr_db=-5: 20.36203169822693 seconds\n",
      "0.5143683160753044\n",
      "Elapsed time for corr_coeff=0.5, Smoothness_order=2, Patchranks=[1, 2], snr_db=0: 15.046984910964966 seconds\n",
      "0.5143683160753044\n",
      "Elapsed time for corr_coeff=0.5, Smoothness_order=2, Patchranks=[1, 2], snr_db=5: 21.28002142906189 seconds\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10 # number of monte-carlo repettions \n",
    "Patchranks_Full = [[1, 2]]\n",
    "for corr_coeff in [0.5]:\n",
    "    for Smoothness_order in range(2,4,2):        \n",
    "        for Patchranks in Patchranks_Full:                        \n",
    "            for snr_db in range(-5,10,5): \n",
    "                start_time = time.time()  # Record start time\n",
    "\n",
    "                # =====================================================\n",
    "                # Subsection 2.1: Set Simulation Parameters\n",
    "                # Inside the loop, this block sets up the specific\n",
    "                # parameters for the current simulation run, such as\n",
    "                # the size of the brain patch, number of time points,\n",
    "                # and SNR level.\n",
    "                # =====================================================\n",
    "\n",
    "                TrueSour_Extent = 5 # Neighborhood orders (source extent)              \n",
    "                maxPatchRank =  np.sum(Patchranks)+1 \n",
    "                n_orders = TrueSour_Extent + 3 # check upto this order\n",
    "                snr_abs = 10**(snr_db/10)\n",
    "                n_timepoints = 50\n",
    "                n_jobs = 7\n",
    "                n_reg_params = 25\n",
    "                smoothing_steps = 1 # just for plot\n",
    "                random_seed = 42 #42\n",
    "                Pert = 70\n",
    "                Singsum = \"False\" \n",
    "                diffusion_parameter = 0.1                    \n",
    "                        \n",
    "                # =====================================================\n",
    "                # Subsection 2.2: Generate Simulated Data\n",
    "                # This block uses the custom `TimeCourse` and\n",
    "                # `SimulationGenerator` classes to create the synthetic\n",
    "                # brain activity. It first generates the source time\n",
    "                # courses with a specific correlation and then uses the\n",
    "                # generator to produce the final sensor-level data (Y)\n",
    "                # and the true underlying source activity (SFull, etc.).\n",
    "                # =====================================================\n",
    "\n",
    "                # Default parameters (Don't change)\n",
    "                generator_args_baseline = dict(\n",
    "                    use_cov = False,\n",
    "                    n_timecourses=5000,\n",
    "                    return_mask = False, \n",
    "                    n_sources = 2,   # 2 simultaneous sources\n",
    "                    n_orders = 0,  # Neighborhodd orders (source extent)\n",
    "                    snr_range = (1,1),  # Signal-to-noise ratio (actual ratio, not dB)\n",
    "                    amplitude_range = (0.5, 1),  # Range of source time course gain \n",
    "                    batch_size = 1,  # No. of samples or iterations\n",
    "                    scale_data = False,  \n",
    "                    n_timepoints = 50,  # No. of time points per sample\n",
    "                    beta_range = (1 ,1),  # Determines the frequency spectrum of each simulted time course (1/f**beta)\n",
    "                    return_info = True,  # Return information on the simulated sources\n",
    "                    inter_source_correlation = 0.5,  # Inter source correlation coefficient roh\n",
    "                    diffusion_parameter = 0.1,  # Diffusion parameter alpha: determines the speed of diffusion, thus shape of extended sources\n",
    "                    random_seed=random_seed,  # Random seed for replicability\n",
    "                    iid_noise=True)  # Sensor noise is IID, so not correlated among channels\n",
    "            \n",
    "                generator_args = deepcopy(generator_args_baseline) # make modification to generator_args dictionary without affecting generator_args_baseline\n",
    "                generator_args[\"snr_range\"] = (snr_abs, snr_abs)\n",
    "                generator_args[\"n_sources\"] = len(Patchranks)\n",
    "                generator_args[\"batch_size\"] = batch_size\n",
    "                generator_args[\"n_timepoints\"]=n_timepoints\n",
    "                generator_args[\"n_orders\"] = (0, TrueSour_Extent+1) # so if TrueSour_Extent=5, then n_orders = (5,6), which is just 5 only\n",
    "                generator_args[\"return_info\"]=True\n",
    "                \n",
    "                TimeCourses = []\n",
    "                TimeCourses = TimeCourse(corr_coeff, batch_size, n_timepoints, np.sum(Patchranks), random_seed)\n",
    "                print(np.corrcoef(TimeCourses[0], TimeCourses[1])[0,1])\n",
    "                \n",
    "                # Patch order are randomly generated in range (0,6)\n",
    "                np.random.seed(random_seed)\n",
    "                random_sequence = np.random.randint(0, TrueSour_Extent+1, size=1000)                \n",
    "                \n",
    "                gen_test = SimulationGenerator(fwd_for, TimeCourses, Patchranks, Smoothness_order, random_sequence, **generator_args)\n",
    "                Y, KQFull, EFull, WFull, SFull, SdotFull, SddotFull, selection, sim_info = [], [], [], [], [], [], [], [], []\n",
    "                Y, KQFull, EFull, WFull, SFull, SdotFull, SddotFull, selection, sim_info = next(gen_test) \n",
    "                \n",
    "                # =====================================================\n",
    "                # Subsection 2.3: Save Data to File\n",
    "                # Here, all the generated data and corresponding\n",
    "                # simulation parameters are bundled into a dictionary.\n",
    "                # A descriptive filename is created, and the dictionary\n",
    "                # is saved to a file using pickle for later analysis.\n",
    "                # =====================================================\n",
    "\n",
    "                # Inside your loop where you generate data, save it along with other variables\n",
    "                data_dict = {}\n",
    "                data_dict['corr_coeff'] = corr_coeff\n",
    "                data_dict['Smoothness_order'] = Smoothness_order\n",
    "                data_dict['Patchranks'] = Patchranks\n",
    "                data_dict['snr_db'] = snr_db\n",
    "                data_dict['Y'] = Y\n",
    "                # data_dict['AAmp'] = AAmp\n",
    "                # data_dict['SS'] = SS\n",
    "                data_dict['selection'] = selection\n",
    "                # data_dict['ssss'] = ssss\n",
    "                # data_dict['TrueVLoc'] = TrueVLoc\n",
    "                data_dict['TimeCourses'] = TimeCourses\n",
    "                data_dict['sim_info'] = sim_info\n",
    "                data_dict['KQFull'] = KQFull\n",
    "                data_dict['EFull'] = EFull\n",
    "                data_dict['WFull'] = WFull\n",
    "                data_dict['SFull'] = SFull\n",
    "                data_dict['SdotFull'] = SdotFull\n",
    "                data_dict['SddotFull'] = SddotFull\n",
    "                \n",
    "                \n",
    "                # Save the dictionary\n",
    "                filename = f\"Data_corr_{corr_coeff}_smooth_{Smoothness_order}_patchranks_{Patchranks}_snr_{snr_db}.pkl\"\n",
    "                save_data(data_dict, folder_path, filename)\n",
    "                \n",
    "                end_time = time.time()  # Record end time\n",
    "                elapsed_time = end_time - start_time\n",
    "                print(f\"Elapsed time for corr_coeff={corr_coeff}, Smoothness_order={Smoothness_order}, Patchranks={Patchranks}, snr_db={snr_db}: {elapsed_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad54b20",
   "metadata": {},
   "source": [
    "#### =========================================================================\n",
    "#### Section 3: Plot Simulated Brain Activity\n",
    "#### After the simulations are complete, this final section visualizes the\n",
    "#### ground truth source activity. It loops through the results of the last\n",
    "#### generated batch, creates an MNE SourceEstimate object for each sample,\n",
    "#### and plots it on a 3D brain model, saving each plot as an image file.\n",
    "#### ========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c045824",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = dict(surface='inflated', hemi='both', background=\"white\", verbose=0, colorbar=False, time_viewer=False)\n",
    "pos_for = pos_from_forward(fwd_for)\n",
    "source_model = fwd_for['src']\n",
    "vertices = [source_model[0]['vertno'], source_model[1]['vertno']]\n",
    "distances = cdist(pos_for, pos_for)\n",
    "argsorted_distance_matrix = np.argsort(distances, axis=1)\n",
    "subject = \"fsaverage\"\n",
    "for i in range(0,batch_size):   \n",
    "    subject = \"fsaverage\"        \n",
    "\n",
    "    # Sum the activity from all sources for visualization\n",
    "\n",
    "    # SS = np.add(SddotFull[i][0], SddotFull[i][1])\n",
    "    SS = np.sum(SddotFull[i], axis=0)\n",
    "    tmin = 0\n",
    "    tstep = 1/1000  \n",
    "    stc = mne.SourceEstimate(SS, vertices, tmin=tmin, tstep=tstep, \n",
    "                                subject=subject, verbose=0)\n",
    "        \n",
    "    stc_ = stc.copy()\n",
    "    stc_.data = SS #abs(stc_.data / np.max(stc_.data, axis=0))\n",
    "        \n",
    "    # Plot the source activity on the brain\n",
    "    \n",
    "    brain = stc_.plot(\n",
    "        hemi=\"both\",\n",
    "        views=[\"ven\"],\n",
    "        brain_kwargs=dict(title=\"Simulated Source Activity\"),\n",
    "        colorbar=True,\n",
    "        cortex=\"low_contrast\",\n",
    "        background=\"white\",\n",
    "    )     \n",
    "    brain.save_image(\"source_plot_{}.png\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f97322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
